{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-transfer-learning",
      "provenance": [],
      "collapsed_sections": [
        "kNENzj-j5Our",
        "lLpbciNq1Ruh",
        "Hg1IK6yBU64q",
        "hIyk1j2m8w0D",
        "XCgCpK16_tS4",
        "sbEM-q-W5e-j"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLS3u1O-wBGa"
      },
      "source": [
        "# 01: Transfer Learning\n",
        "\n",
        "Welcome to the course on Deep Learning with Multiple Objectives!\n",
        "\n",
        "<img width=400 src=\"https://www.dropbox.com/s/unl81onqf0kz02w/fig2.png?dl=1\">\n",
        "\n",
        "## Plan for today\n",
        "\n",
        "1. Go through course outline, logistics, etc.\n",
        "2. Introduction \n",
        "  * Walk through PyTorch basics to make sure we are on the same page\n",
        "3. Transfer Learning\n",
        "  * Excite you about transfer learning\n",
        "4. Home-work\n",
        "\n",
        "Next time: Implementing Transformer from scratch and mini-project ideas discussion!\n",
        "\n",
        "## Questions?\n",
        "\n",
        "Do you have any questions about the lecture? (probably not yet, but we will try to always start with a discussion about what questions you had about papers and the lecture)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNENzj-j5Our"
      },
      "source": [
        "# 1. Course logistics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hseoo3v15N0j"
      },
      "source": [
        "(See README.md on github)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLpbciNq1Ruh"
      },
      "source": [
        "# 2. Introduction to \"Static World\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsbkV3gs1BOA"
      },
      "source": [
        "The objective is to get familiar with PyTorch and the concept (and the importance) of transfer learning.\n",
        "\n",
        "The traditional approach to solving classifcation tasks is to obtain large quantities (ImageNet is ~14M images) of supervised data and learn a machine learning model.\n",
        "\n",
        "<center><img src=\"https://i0.wp.com/semiengineering.com/wp-content/uploads/2019/10/Synopsys_computer-vision-processors-EV7-Fig2-ImageNet.jpeg?ssl=1\"></center>\n",
        "\n",
        "What if we want to quickly learn based on a small sample of data?\n",
        "\n",
        "<center><img src=\"https://www.dropbox.com/s/7gvah7w7h1jvkcm/fig1.png?dl=1\"></center>\n",
        "\n",
        "How did we manage to complete this task? We leverage prior experience. We know we are in the *Static World*. \n",
        "\n",
        "Transfer learning is a research agenda that is at the essence of why deep learning is important. Transfer learning is usually defined as applying knowledge gained in one task to another task. Deep learning is important because it enables acquiring broadly generalizing algorithms (models).\n",
        "\n",
        "<center><img src=\"https://www.dropbox.com/s/v1trzeu5dw2834x/fig3.png?dl=1\"></center>\n",
        "\n",
        "Partially adapted from https://cs330.stanford.edu/slides/cs330_multitask_transfer_2020.pdf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg1IK6yBU64q"
      },
      "source": [
        "# 3. Setup\n",
        "\n",
        "Please walk through these steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-Oh8529WrRP"
      },
      "source": [
        "# 0. Clone, install & configure some software\n",
        "\n",
        "! git clone https://github.com/asyml/vision-transformer-pytorch\n",
        "! pip install dotmap\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"vision-transformer-pytorch\")\n",
        "sys.path.append(\"vision-transformer-pytorch/src\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP1bPcecVIru"
      },
      "source": [
        "# 1. Generic imports\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "## Torch requires specifying where computation happens\n",
        "import torch.nn as nn\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import gc; \n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from dotmap import DotMap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL5JUa4bWp4x"
      },
      "source": [
        "# 2. Imports from Vision Transformer repository\n",
        "\n",
        "from utils import setup_device, accuracy, MetricTracker, TensorboardWriter\n",
        "from src.model import VisionTransformer\n",
        "from src.config import get_b16_config, get_train_config\n",
        "from src.checkpoint import load_checkpoint\n",
        "from src.data_loaders import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUqe_Rx-W9X1"
      },
      "source": [
        "# 3. Finally, make sure you have ViT pretrained weights\n",
        "\n",
        "\"\"\"\n",
        "Please grab imagenet21k+imagenet2012_ViT-B_16.pth from https://drive.google.com/drive/folders/1azgrD1P413pXLJME0PjRRU-Ez-4GWN-S \n",
        "Two ways:\n",
        "\n",
        "  * (recommended) create copy of imagenet21k+imagenet2012_ViT-B_16.pth from https://drive.google.com/drive/folders/1azgrD1P413pXLJME0PjRRU-Ez-4GWN-S and link your google drive\n",
        "  * (discouraged) you can download using \"!wget https://www.dropbox.com/s/ihi643hkcer2cu5/imagenet21k%2Bimagenet2012_ViT-B_16.pth?dl=1\"\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIyk1j2m8w0D"
      },
      "source": [
        "# 4. PyTorch Introduction\n",
        "\n",
        "Quick question: How many of you have trained a deep convolutional neural network using PyTorch or a similar framework?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zooshMkRAOeX"
      },
      "source": [
        "# 1. Visualize dataset\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "## WRITEME Show first 4 images and their labels. ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdNA8Ff06AI8"
      },
      "source": [
        "# 2. Define the model\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = ## WRITEME ##\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "assert output.shape[-1] == 10\n",
        "print(\"Congratulations!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnXFaibj_Yur"
      },
      "source": [
        "# 3. Train the network\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ## WRITEME ##\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 6000 == 5999:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 6000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwzprxfl_btu"
      },
      "source": [
        "# 4. Visualize predictions\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1qVAnXOD5sh"
      },
      "source": [
        "# 5. Calculate accuracy \n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "\n",
        "assert correct / total > 0.5\n",
        "print(\"Congratulations!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJEgk_f3_eRV"
      },
      "source": [
        "(The above was based on https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html, but do not look up the answer as it defeats the purpose of the exercise to get you on the same page.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCgCpK16_tS4"
      },
      "source": [
        "# 5. Transfer Learning: Fine-tune a SOTA model:\n",
        "\n",
        "Vision Transformer is a very recently proposed model by Google Brain [quick \"whiteboard\" presentation].\n",
        "\n",
        "Please complete the code below, and then complete the exercises.\n",
        "\n",
        "(Based on https://github.com/asyml/vision-transformer-pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alygD-U9LDu3"
      },
      "source": [
        "# 1. Define Config\n",
        "\n",
        "# Some defaults taken form README.md in https://github.com/asyml/vision-transformer-pytorch\n",
        "config = get_b16_config(DotMap())\n",
        "config.image_size = 384\n",
        "config.num_classes = 10\n",
        "config.lr = 0.005\n",
        "config.warmup_steps = 10 \n",
        "config.wd = 0.0\n",
        "config.num_classes = 10\n",
        "config.train_steps_per_epoch = 100\n",
        "config.epochs = 3\n",
        "config.batch_size = 8\n",
        "config.num_workers = 1\n",
        "config.data_dir = \"data\"\n",
        "# Make sure this path exists!\n",
        "config.checkpoint_path = \"drive/imagenet21k+imagenet2012_ViT-B_16.pth\" \n",
        "assert len(config.checkpoint_path) == 0 or os.path.exists(config.checkpoint_path)\n",
        "config.dataset = \"CIFAR10\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XsHiC4gJ57U"
      },
      "source": [
        "# 2. Define model\n",
        "\n",
        "# Warning: do not create more than a single instance. Otherwise GPU might run out of\n",
        "model = VisionTransformer(\n",
        "          image_size=(config.image_size, config.image_size),\n",
        "          patch_size=(config.patch_size, config.patch_size),\n",
        "          emb_dim=config.emb_dim,\n",
        "          mlp_dim=config.mlp_dim,\n",
        "          num_heads=config.num_heads,\n",
        "          num_layers=config.num_layers,\n",
        "          num_classes=config.num_classes,\n",
        "          attn_dropout_rate=config.attn_dropout_rate,\n",
        "          dropout_rate=config.dropout_rate)\n",
        "_ = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9_UZQc-aGM3"
      },
      "source": [
        "# 3. Get dataloaders\n",
        "\n",
        "train_dataloader = eval(\"{}DataLoader\".format(config.dataset))(\n",
        "                data_dir=os.path.join(config.data_dir, config.dataset),\n",
        "                image_size=config.image_size,\n",
        "                batch_size=config.batch_size,\n",
        "                num_workers=config.num_workers,\n",
        "                split='train')\n",
        "valid_dataloader = eval(\"{}DataLoader\".format(config.dataset))(\n",
        "                data_dir=os.path.join(config.data_dir, config.dataset),\n",
        "                image_size=config.image_size,\n",
        "                batch_size=config.batch_size,\n",
        "                num_workers=config.num_workers,\n",
        "                split='val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PUYJg9Y8BKh"
      },
      "source": [
        "# 4. Load in checkpoint\n",
        "if config.checkpoint_path:\n",
        "    state_dict = load_checkpoint(config.checkpoint_path)\n",
        "    print(state_dict['classifier.weight'].size(0))\n",
        "    if config.num_classes != state_dict['classifier.weight'].size(0):\n",
        "        del state_dict['classifier.weight']\n",
        "        del state_dict['classifier.bias']\n",
        "        print(\"re-initialize fc layer\")\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "    else:\n",
        "        model.load_state_dict(state_dict)\n",
        "    print(\"Load pretrained weights from {}\".format(config.checkpoint_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FaZOTt0tUx2"
      },
      "source": [
        "# 5. Is everything fine?\n",
        "x, y = next(train_dataloader.__iter__())\n",
        "x = x.to(device)\n",
        "y_pred = model.forward(x[0:4])\n",
        "assert y_pred is not None\n",
        "print(\"Worked!\")\n",
        "del y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRin6PtgTqvo"
      },
      "source": [
        "# 6. Train and evaluate the model \n",
        "\n",
        "# this is important in colab - it keeps a single session that can fill up GPU memory\n",
        "gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "# training criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# create optimizers and learning rate scheduler\n",
        "optimizer = torch.optim.SGD(\n",
        "    params=model.parameters(),\n",
        "    lr=config.lr,\n",
        "    weight_decay=config.wd,\n",
        "    momentum=0.9)\n",
        "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer=optimizer,\n",
        "    max_lr=config.lr,\n",
        "    pct_start=config.warmup_steps / (config.train_steps_per_epoch * (config.epochs + 1)),\n",
        "    total_steps=config.train_steps_per_epoch * (config.epochs + 1))\n",
        "\n",
        "# some boilerplate\n",
        "metric_names = ['loss', 'acc1']\n",
        "writer = TensorboardWriter(\".\", config.tensorboard)\n",
        "train_metrics = MetricTracker(*[metric for metric in metric_names], writer=writer)\n",
        "valid_metrics = MetricTracker(*[metric for metric in metric_names], writer=writer)\n",
        "\n",
        "# start training\n",
        "print(\"start training\")\n",
        "best_acc = 0.0\n",
        "\n",
        "def train_epoch(epoch, model, data_loader, criterion, optimizer, lr_scheduler, metrics, device=torch.device('cpu'), steps=np.inf):\n",
        "    metrics.reset()\n",
        "\n",
        "    # training loop\n",
        "    for batch_idx, (batch_data, batch_target) in enumerate(data_loader):\n",
        "        batch_data = batch_data.to(device)\n",
        "        batch_target = batch_target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch_pred = model(batch_data)\n",
        "        loss = criterion(batch_pred, batch_target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        acc1, = accuracy(batch_pred, batch_target, topk=(1,))\n",
        "\n",
        "        metrics.writer.set_step((epoch - 1) * len(data_loader) + batch_idx)\n",
        "        metrics.update('loss', loss.item())\n",
        "        metrics.update('acc1', acc1.item())\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(\"Train Epoch: {:03d} Batch: {:05d}/{:05d} Loss: {:.4f} Acc@1: {:.2f}\"\n",
        "                    .format(epoch, batch_idx, min(len(data_loader), steps), loss.item(), acc1.item()))\n",
        "            \n",
        "\n",
        "        if batch_idx > steps:\n",
        "          break\n",
        "    return metrics.result()\n",
        "\n",
        "\n",
        "def valid_epoch(epoch, model, data_loader, criterion, metrics, device=torch.device('cpu'), steps=np.inf):\n",
        "    metrics.reset()\n",
        "    losses = []\n",
        "    acc1s = []\n",
        "    acc5s = []\n",
        "    # validation loop\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (batch_data, batch_target) in enumerate(data_loader):\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_target = batch_target.to(device)\n",
        "\n",
        "            batch_pred = model(batch_data)\n",
        "            loss = criterion(batch_pred, batch_target)\n",
        "            acc1,  = accuracy(batch_pred, batch_target, topk=(1,))\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            acc1s.append(acc1.item())\n",
        "\n",
        "            if batch_idx > steps:\n",
        "              break\n",
        "\n",
        "    loss = np.mean(losses)\n",
        "    acc1 = np.mean(acc1s)\n",
        "    metrics.writer.set_step(epoch, 'valid')\n",
        "    metrics.update('loss', loss)\n",
        "    metrics.update('acc1', acc1)\n",
        "    return metrics.result()\n",
        "\n",
        "for epoch in range(1, config.epochs + 1):\n",
        "    log = {'epoch': epoch}\n",
        "\n",
        "    # train the model\n",
        "    model.train()\n",
        "    result = train_epoch(epoch, model, train_dataloader, criterion, optimizer, lr_scheduler, train_metrics, device, steps=config.train_steps_per_epoch)\n",
        "    log.update(result)\n",
        "    print(\"Finished epoch\")\n",
        "\n",
        "    # validate the model\n",
        "    model.eval()\n",
        "    result = valid_epoch(epoch, model, valid_dataloader, criterion, valid_metrics, device, steps=50)\n",
        "    log.update(**{'val_' + k: v for k, v in result.items()})\n",
        "\n",
        "    # print logged informations to the screen\n",
        "    for key, value in log.items():\n",
        "        print('    {:15s}: {}'.format(str(key), value))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tH945EztzLU"
      },
      "source": [
        "Fine-tuning has slightly different challenges than training model from scratch. The following two exercises are designed to provide opportunity to experiment with fine-tuning. \n",
        "\n",
        "When you are done please raise hand, and you can go.\n",
        "\n",
        "## Exercise 0: Train without pretraining\n",
        "\n",
        "Try training the model without using the checkpoint. Did it work?\n",
        "\n",
        "## Exercise 1: Improve the result\n",
        "\n",
        "Tune different hyperparameters (learning rate? number of epochs? ...) to achieve better performance than 93%. Can you beat state-of-the-art methods on CIFAR-10 that train only on CIFAR-10?\n",
        "\n",
        "Please write results on the \"whiteboard\". This is not a competition of course, just curious what tricks are important. Fine-tuning of large pretrained models is tricky (spoiler alert: this is one idea for project).\n",
        "\n",
        "## Exercise 2: Training only the final classifier\n",
        "\n",
        "A common strategy in fine-tuning is to only unfreeze a subset of the weights. Train a variant of the model where you fine-tune only the final classifier. What performance did it reach?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbEM-q-W5e-j"
      },
      "source": [
        "# 6. Homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVJOyVoij5vk"
      },
      "source": [
        "* (1p) Read https://machinelearningmastery.com/transfer-learning-for-deep-learning/\n",
        "\n",
        "* (2p) Read https://arxiv.org/pdf/2005.14165.pdf (you can skip Section 4 and Section 6. Feel free to skim over some of the results) and   https://arxiv.org/abs/2010.11929.\n",
        "\n",
        "\n",
        "\n",
        "  Then, for each write a concise summary of the paper that answers (note: you should read the whole paper, not only answer these questions!) the following questions:\n",
        "\n",
        "    * What problem did the authors propose to tackle (pay close attention to Introduction)\n",
        "  \n",
        "    * What was previosly popular approach to solve this problem?\n",
        "  \n",
        "    * What is the method and motivation for using this method?\n",
        "  \n",
        "    * What are topics for the future work?\n",
        "\n",
        "    * What question you would ask the author (we will discuss some during the next class)\n",
        "\n",
        "  Please send the summaries to my email.\n",
        "\n",
        "  Fair warning: You might be asked to present answers.\n",
        "\n",
        "* Find a group of 2 to 3. This will be the group you will be working on throughout the semester on the mini-project and the final project. It is fine to change the group after the mini-project. \n",
        "\n",
        "* If you are unfamiliar with PyTorch, please walkthrough https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html in detail"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX4QGicrrGpm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}